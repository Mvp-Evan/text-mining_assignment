@article{yao2019docred,
  title={DocRED: A large-scale document-level relation extraction dataset},
  author={Yao, Yuan and Ye, Deming and Li, Peng and Han, Xu and Lin, Yankai and Liu, Zhenghao and Liu, Zhiyuan and Huang, Lixin and Zhou, Jie and Sun, Maosong},
  journal={arXiv preprint arXiv:1906.06127},
  year={2019}
}

@article{xiao2021sais,
  title={SAIS: supervising and augmenting intermediate steps for document-level relation extraction},
  author={Xiao, Yuxin and Zhang, Zecheng and Mao, Yuning and Yang, Carl and Han, Jiawei},
  journal={arXiv preprint arXiv:2109.12093},
  year={2021}
}

@article{zeng2020double,
  title={Double graph based reasoning for document-level relation extraction},
  author={Zeng, Shuang and Xu, Runxin and Chang, Baobao and Li, Lei},
  journal={arXiv preprint arXiv:2009.13752},
  year={2020}
}

@article{ma2023dreeam,
  title={DREEAM: Guiding Attention with Evidence for Improving Document-Level Relation Extraction},
  author={Ma, Youmi and Wang, An and Okazaki, Naoaki},
  journal={arXiv preprint arXiv:2302.08675},
  year={2023}
}

@inproceedings{xu2021entity,
  title={Entity structure within and throughout: Modeling mention dependencies for document-level relation extraction},
  author={Xu, Benfeng and Wang, Quan and Lyu, Yajuan and Zhu, Yong and Mao, Zhendong},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={16},
  pages={14149--14157},
  year={2021}
}

@article{tan2022document,
  title={Document-level relation extraction with adaptive focal loss and knowledge distillation},
  author={Tan, Qingyu and He, Ruidan and Bing, Lidong and Ng, Hwee Tou},
  journal={arXiv preprint arXiv:2203.10900},
  year={2022}
}

@article{wang2019fine,
  title={Fine-tune bert for docred with two-step process},
  author={Wang, Hong and Focke, Christfried and Sylvester, Rob and Mishra, Nilesh and Wang, William},
  journal={arXiv preprint arXiv:1909.11898},
  year={2019}
}

@article{han2020novel,
  title={A novel document-level relation extraction method based on BERT and entity information},
  author={Han, Xiaoyu and Wang, Lei},
  journal={Ieee Access},
  volume={8},
  pages={96912--96919},
  year={2020},
  publisher={IEEE}
}

@inproceedings{cai2016bidirectional,
  title={Bidirectional recurrent convolutional neural network for relation classification},
  author={Cai, Rui and Zhang, Xiaodong and Wang, Houfeng},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={756--765},
  year={2016}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{TanQingyu2022RD-A,
author = {Tan, Qingyu and Xu, Lu and Bing, Lidong and Hwee Tou Ng and Sharifah Mahani Aljunied},
address = {Ithaca},
copyright = {2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2331-8422},
journal = {arXiv.org},
language = {eng},
publisher = {Cornell University Library, arXiv.org},
title = {Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction},
year = {2022},
}

@inproceedings{elsahar2018t,
  title={T-rex: A large scale alignment of natural language with knowledge base triples},
  author={Elsahar, Hady and Vougiouklis, Pavlos and Remaci, Arslen and Gravier, Christophe and Hare, Jonathon and Laforest, Frederique and Simperl, Elena},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@article{WangHong2019FBfD,
author = {Wang, Hong and Focke, Christfried and Sylvester, Rob and Mishra, Nilesh and Wang, William},
address = {Ithaca},
copyright = {2019. This work is published under http://arxiv.org/licenses/nonexclusive-distrib/1.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2331-8422},
journal = {arXiv.org},
language = {eng},
publisher = {Cornell University Library, arXiv.org},
title = {Fine-tune Bert for DocRED with Two-step Process},
year = {2019},
}

@book{alma992984185801101631,
author = {Albalate, Amparo. and Minker, Wolfgang.},
address = {London},
booktitle = {Semi-supervised and unsupervised machine learning : novel strategies},
isbn = {9781118557693},
keywords = {COMPUTERS -- Enterprise Applications -- Business Intelligence Tools},
language = {eng},
lccn = {2010040730},
publisher = {ISTE},
series = {ISTE},
title = {Semi-supervised and unsupervised machine learning : novel strategies },
year = {2011},
}